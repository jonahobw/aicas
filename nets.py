import pandas as pd
from pathlib import Path

def best_model(path:Path, metric:str):
    '''
    Parses a logs.csv file generated by shrinkbench to get path to the best model from a training process.

    :param path: path to the root directory generated by shrinkbench, has a file called logs.csv
    :param metric: how to compare models to find the best one, it is {train_, val_}{loss, acc1, acc5}
    :return: a path to the file that stores the model with the best metric
    '''

    if not isinstance(path, Path):
        path = Path(path)

    csv_path = path / 'logs.csv'
    df = pd.read_csv(csv_path)
    df = df[df['epoch'] >= 0]
    best_epoch = None

    if 'loss' in metric:
        best_epoch = int(df[df[metric] == df[metric].min()]['epoch'])
    if 'acc' in metric:
        best_epoch = int(df[df[metric] == df[metric].max()]['epoch'])

    return path / 'checkpoints' / f'checkpoint-{best_epoch}.pt'

def get_hyperparameters(model_type, num_workers=4):
    """
    Returns the training and pruning hyperparameters for a model
    :param model_type:
    :return:
    """
    if 'resnet' in model_type or 1:
        model_type = 'resnet'

    model_kwargs = {
        'resnet': {
            'train':{
                'optim': 'SGD',
                'epochs': 300,
                'lr': 1e-1,
                'weight_decay': 1e-4
            },
            'prune': {
                'optim': 'SGD',
                'epochs': 40,
                'lr': 1e-3,
                'weight_decay': 1e-4
            }
        }
    }

    common_kwargs = {
        'dl_kwargs': {
            'batch_size': 128,
            'pin_memory': False,
            'num_workers': num_workers
        },
        'save_freq': 1000,
        'early_stop': None
    }

    train_kwargs = {
        **common_kwargs,
        'train_kwargs': {
            **model_kwargs[model_type]['train']
        },
        'lr_schedule': get_lr_schedule(model_kwargs[model_type]['train']['lr'])
    }

    prune_kwargs = {
        **common_kwargs,
        'train_kwargs': {
            **model_kwargs[model_type]['prune']
        }
    }

    return train_kwargs, prune_kwargs

def get_lr_schedule(intial_rate):
    def lr_schedule(epoch):
        if epoch < intial_rate * 0.5:
            return intial_rate
        if epoch > intial_rate * 0.5 and epoch < intial_rate * 0.75:
            return intial_rate/10
        return intial_rate/100

    return lr_schedule

if __name__ == '__main__':
    path = r'C:\Users\Jonah\Desktop\Jonah\0Grad_1\Research\code\aicas\experiments\experiment_0\ResNet18\CIFAR10\resnet18\20211017-211025-E50M-5e120182ebb2006439029f4a2571acd0'
    for m in ['train_loss','train_acc1','train_acc5','val_loss','val_acc1','val_acc5']:
        print(best_model(path, m))